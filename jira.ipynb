{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jira import JIRA\n",
    "import re\n",
    "\n",
    "# Jira credentials\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "url = \"\"\n",
    "\n",
    "# Create a Jira connection\n",
    "jira = JIRA(server=url, basic_auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scds_ticket(issue):\n",
    "    try:\n",
    "        summary = issue.raw[\"fields\"][\"summary\"]\n",
    "        status = issue.raw[\"fields\"][\"status\"][\"name\"]\n",
    "\n",
    "        if issue.raw[\"fields\"].get(\"customfield_10140\"):\n",
    "            analyst = issue.raw[\"fields\"][\"customfield_10140\"][0][\"displayName\"]\n",
    "        else:\n",
    "            analyst = \"Unassigned\"\n",
    "\n",
    "        parent_key = issue.raw[\"fields\"][\"parent\"][\"key\"]\n",
    "        # get an issue by name\n",
    "        parent_issue = jira.issue(parent_key)\n",
    "        epic_batch_name = parent_issue.raw[\"fields\"][\"parent\"][\"fields\"][\"summary\"]\n",
    "\n",
    "        return {\n",
    "            \"summary\": summary,\n",
    "            \"status\": status,\n",
    "            \"analyst\": analyst,\n",
    "            \"epic_batch_name\": epic_batch_name,\n",
    "        }\n",
    "    except Exception as ex:\n",
    "        return\n",
    "\n",
    "\n",
    "def parse_batch(s):\n",
    "    pattern = re.compile(r\"batch(\\d+)\")\n",
    "    match = pattern.search(s)\n",
    "    batch_number = match.group(1)\n",
    "    return batch_number\n",
    "\n",
    "\n",
    "def parse_shortname(s):\n",
    "    pattern = re.compile(r\".*deliverables/(.*)-README.txt\")\n",
    "    match = pattern.search(s)\n",
    "    batch_number = match.group(1)\n",
    "    return batch_number\n",
    "\n",
    "\n",
    "def parse_dataset(s):\n",
    "    pattern = re.compile(r\"/data/batch\\d/(.*)/deliverables.*\")\n",
    "    match = pattern.search(s)\n",
    "    batch_number = match.group(1)\n",
    "    return batch_number\n",
    "\n",
    "\n",
    "def compose_name(shortname, dataset, batch_no):\n",
    "    return f\"{shortname} ({dataset}) batch{batch_no} var table patch\"\n",
    "\n",
    "\n",
    "def create_issue_in_epic(\n",
    "    title, description=None, parent_key=\"CURATIONBD-1071\", project_key=\"CURATIONBD\"\n",
    "):\n",
    "    # Issue details\n",
    "    issue_data = {\n",
    "        \"project\": {\"key\": project_key},\n",
    "        \"summary\": title,\n",
    "        \"description\": description,\n",
    "        \"issuetype\": {\"name\": \"Task\"},\n",
    "    }\n",
    "\n",
    "    # Create the issue\n",
    "    new_issue = jira.create_issue(fields=issue_data)\n",
    "\n",
    "    # Link to the epic\n",
    "    new_issue.update(fields={\"parent\": {\"key\": parent_key}})\n",
    "\n",
    "    print(f\"Issue created successfully. Key: {new_issue.key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_epic_tickets(batch_name = 'Batch 8', epic_name):\n",
    "    issues = jira.search_issues(\n",
    "        \"project = CURATIONBD\"\n",
    "        \" AND issuetype = Subtask\"\n",
    "        f' AND \"Batch[Dropdown]\" = \"{batch_name}\"'\n",
    "        ' AND \"Workflow[Dropdown]\" = Bioinformatics'\n",
    "        \" AND status not in (Blocked)\",\n",
    "        maxResults=None,\n",
    "    )\n",
    "    # parse issues\n",
    "    parsed_issues = [parse_scds_ticket(issue) for issue in issues]\n",
    "    # remove missing issues\n",
    "    parsed_issues = [issue for issue in parsed_issues if issue]\n",
    "    # filter to just one epic batch\n",
    "    parsed_issues = [\n",
    "        issue for issue in parsed_issues if issue[\"epic_batch_name\"] == epic_name\n",
    "    ]\n",
    "    return parsed_issues\n",
    "\n",
    "def status_report(parsed_issues):\n",
    "    # list all statuses\n",
    "    status = {\n",
    "        \"To Do\": 0,\n",
    "        \"4. Bio Download\": 0,\n",
    "        \"5. Bio Processing\": 0,\n",
    "        \"6. Bio formatting\": 0,\n",
    "        \"6.1 Bio QC\": 0,\n",
    "        \"7. Delivery QC\": 0,\n",
    "        \"Done\": 0,\n",
    "    }\n",
    "\n",
    "    report = {}\n",
    "\n",
    "    for issue in parsed_issues:\n",
    "        this_issue = issue\n",
    "        this_analyst = this_issue[\"analyst\"]\n",
    "\n",
    "        if this_analyst not in report:\n",
    "            report[this_analyst] = status.copy()\n",
    "        report[this_analyst][this_issue[\"status\"]] += 1\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_epic_tickets(\"Year 2: Batch 8b Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
